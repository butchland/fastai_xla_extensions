{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp cifar_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR Loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "STATUS: SUPER EARLY ALPHA\n",
    "\n",
    "This package is NOT yet ready for PUBLIC CONSUMPTION. Use at your own RISK!!!!\n",
    "\n",
    "Everything, including the API (and even\n",
    "the existence of this module) are subject\n",
    "to breaking change...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are utilities for adapting Pytorch/torchvision Datasets to be used in fastai TPU training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r\u001b[K     |██████▏                         | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 34.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 21.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
      "\u001b[?25h  Building wheel for fastai (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -Uqq git+https://github.com/fastai/fastai.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fastai...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!curl -s https://course19.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.7.0+cu101\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.3.1\n",
      "torchvision==0.8.1+cu101\n",
      "fastai==2.2.5\n",
      "fastcore==1.3.19\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrlock==0.5\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip freeze | grep torch\n",
    "!pip freeze | grep fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# Start of kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_torch_dsets(path, torch_dset):\n",
    "    \"\"\"Download cifar10 datasets using torchvision utils\n",
    "\n",
    "       Arguments:\n",
    "           path (pathlib.Path): path to download the dataset (aka root)\n",
    "    \"\"\"\n",
    "    train_dataset = torch_dset(\n",
    "        root=path,\n",
    "        train=True,\n",
    "        download=True\n",
    "\n",
    "        )\n",
    "    test_dataset = torch_dset(\n",
    "        root=path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        )\n",
    "    return train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import numpy as np\n",
    "import torchvision.datasets.utils as tv_utils\n",
    "import torchvision.datasets.cifar as cifar_dsets\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.fastai/data/cifar/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca4b40f241a4588b8f4e965a3b85114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.fastai/data/cifar/cifar-10-python.tar.gz to /root/.fastai/data/cifar\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/root/.fastai/data/cifar/cifar-10-python.tar.gz'),Path('/root/.fastai/data/cifar/cifar-10-batches-py')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "from fastai.data.external import Config\n",
    "from pathlib import Path\n",
    "import torchvision.datasets.cifar as cifar_dset\n",
    "# patch pathlib with fastai goodies\n",
    "import fastcore.xtras \n",
    "cfg = Config()\n",
    "cifar_root = cfg.data_path/'cifar'\n",
    "# cifar_root = Path('/tmp/cifar')\n",
    "cifar_root.mkdir(parents=True,exist_ok=True)\n",
    "cifar_root.ls()\n",
    "_ = download_torch_dsets(cifar_root, cifar_dset.CIFAR10)\n",
    "cifar_root.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_torch_items(downloaded_list, path, check=False):\n",
    "    \"\"\"loads cifar test/train items into tuple(data, target)\n",
    "\n",
    "       scrobbled together from torch.data.utils.datasets.CIFAR10 code\n",
    "       https://pytorch.org/docs/stable/_modules/torchvision/datasets/cifar.html#CIFAR10\n",
    "\n",
    "       Arguments:\n",
    "           downloaded_list : a list of file names with their checksum, see CIFAR10.train_list or CIFAR10.test_list.\n",
    "           path (pathlib.Path): the root path where the dataset was downloaded\n",
    "           check(bool, optional): whether to perform an integrity check on the downloaded files (default: False)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    targets = []\n",
    "    # now load the picked numpy arrays\n",
    "    for file_name, checksum in downloaded_list:\n",
    "        file_path = path/cifar_dsets.CIFAR10.base_folder/file_name\n",
    "        if check and not tv_utils.check_integrity(file_path, checksum):\n",
    "            raise RuntimeError(\n",
    "        f'Data checksum failed for file:{file_path} checksum:{checksum}')\n",
    "        with open(file_path, 'rb') as f:\n",
    "            entry = pickle.load(f, encoding='latin1')\n",
    "            data.append(entry['data'])\n",
    "            if 'labels' in entry:\n",
    "                targets.extend(entry['labels'])\n",
    "            else:\n",
    "                targets.extend(entry['fine_labels'])\n",
    "\n",
    "    data = np.vstack(data).reshape(-1, 3, 32, 32)\n",
    "    data = data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "tst_data, tst_targets = load_torch_items(cifar_dsets.CIFAR10.test_list, cifar_root, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(tst_data.shape,(10000,32,32,3))\n",
    "test_eq(len(tst_targets),10000)\n",
    "assert isinstance(tst_data,np.ndarray)\n",
    "assert isinstance(tst_targets[0], int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO: incorporate list of classes into dataloaders vocab and decodes\n",
    "\n",
    "from fastcore.foundation import L\n",
    "def load_classes(path):\n",
    "    \"\"\"Load classes to used to map categories to target labels\"\"\"\n",
    "    base_folder = cifar_dsets.CIFAR10.base_folder\n",
    "    meta = cifar_dsets.CIFAR10.meta\n",
    "    file_path = path/base_folder/meta['filename']\n",
    "    if not tv_utils.check_integrity(file_path, meta['md5']):\n",
    "        raise RuntimeError('Dataset metadata file not found or corrupted.' +\n",
    "                           ' You can use download=True to download it')\n",
    "    data = {}\n",
    "    with open(file_path, 'rb') as infile:\n",
    "        data = pickle.load(infile, encoding='latin1')\n",
    "    classes = data[meta['key']]\n",
    "#     class_for i, _class in enumerato_idx = {_class: i te(classes)}\n",
    "    return L(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "classes = load_classes(cifar_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "test_eq(len(classes),10); classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "train_items = load_torch_items(cifar_dsets.CIFAR10.train_list, cifar_root, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastcore.transform import Transform\n",
    "import torchvision.transforms.functional as TVF\n",
    "import torch\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CifarNP2ImageTransform(Transform):\n",
    "    def encodes(self, o:np.ndarray) -> None:\n",
    "        return PIL.Image.fromarray(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Int2TensorTransform(Transform):\n",
    "    def encodes(self, o: int) -> None:\n",
    "        return torch.tensor(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CifarImageTransform(Transform):\n",
    "    def encodes(self, o: PIL.Image) -> None:\n",
    "        return TVF.to_tensor(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CifarImage2FloatTransform(Transform):\n",
    "    def encodes(self, o: torch.Tensor) -> None:\n",
    "        return o.float().div_(255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import torchvision as thv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_torch_tfms():\n",
    "    norm = thv.transforms.Normalize(\n",
    "        mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "    transform_train = thv.transforms.Compose([\n",
    "        thv.transforms.RandomCrop(32, padding=4),\n",
    "        thv.transforms.RandomHorizontalFlip(),\n",
    "        thv.transforms.ToTensor(),\n",
    "        norm,\n",
    "    ])\n",
    "    transform_test = thv.transforms.Compose([\n",
    "        thv.transforms.ToTensor(),\n",
    "        norm,\n",
    "    ])\n",
    "    return transform_train, transform_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_train_tfms, th_test_tfms = make_torch_tfms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastcore.transform import ItemTransform\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CifarTupleTransform(ItemTransform):\n",
    "    def __init__(self, x_tfm, y_tfm):\n",
    "        store_attr()\n",
    "    def encodes(self,xy):\n",
    "        return [self.x_tfm(xy[0]), self.y_tfm(xy[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import torch.utils.data as th_data\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO: Use TupleTorchDS to create torch dataloaders\n",
    "\n",
    "class TupleTorchDS(th_data.Dataset):\n",
    "    def __init__(self, items, x_tfm=None, y_tfm=None):\n",
    "        store_attr()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x,y = self.items[index]\n",
    "        x = self.x_tfm(x) if self.x_tfm is not None else x\n",
    "        y = self.y_tfm(y) if self.y_tfm is not None else y\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastcore.transform import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "i2t_tfm = Int2TensorTransform() # cnvt int -> torch.tensor\n",
    "cfnp2img_tfm = CifarNP2ImageTransform() # cnvt ndarray -> PIL.Image\n",
    "cfimg_tfm = CifarImageTransform() # cnvt PIL.Image -> torch.tensor\n",
    "cfimg2float_tfm = CifarImage2FloatTransform() # cnvt tensor int -> float + div 255\n",
    "\n",
    "def make_cifar_item_tfm(th_img_tfms=None):\n",
    "    img_tfms = [cfnp2img_tfm]\n",
    "    if th_img_tfms is not None:\n",
    "        # assumes th_img_tfms incl ToTensor (cnvt2 PIL.Image -> tensor + div by 255)\n",
    "        img_tfms += [th_img_tfms]\n",
    "    else:\n",
    "        img_tfms += [cfimg_tfm, cfimg2float_tfm]\n",
    "\n",
    "    return CifarTupleTransform(x_tfm=Pipeline(img_tfms), y_tfm=i2t_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fastai_tfms = make_cifar_item_tfm()\n",
    "mixed_fastai_train_tfms = make_cifar_item_tfm(th_train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastai.data.core import TfmdDL\n",
    "from fastai.data.core import TfmdLists\n",
    "from fastcore.foundation import L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_cifar_tls(file_list, path, item_tfm, check=True):\n",
    "    data, targets = load_torch_items(file_list, path, check=check)\n",
    "    item_tuples = L(data,targets).zip()\n",
    "    tls = TfmdLists(item_tuples,[item_tfm])\n",
    "    return tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_cifar_dl(file_list, path, th_img_tfms=None, check=True, bs=64, **kwargs):\n",
    "    item_tfm = make_cifar_item_tfm(th_img_tfms)\n",
    "    tls = make_cifar_tls(file_list, path, item_tfm, check=check)\n",
    "    dl = TfmdDL(tls,bs=bs, **kwargs)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tls = make_cifar_tls(cifar_dsets.CIFAR10.train_list,\n",
    "                           cifar_root,mixed_fastai_train_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose:\n",
       "encodes: (object,object) -> Composedecodes: "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tls.tfms[0].x_tfm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl1 = make_cifar_dl(cifar_dsets.CIFAR10.train_list, cifar_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti \n",
    "from fastai.data.core import DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_fastai_cifar_dls(path, bs=64, check=True, device=None, **kwargs):\n",
    "    train_tfm, test_tfm = make_torch_tfms()\n",
    "    train_dl = make_cifar_dl(\n",
    "        cifar_dsets.CIFAR10.train_list,\n",
    "        path,\n",
    "        train_tfm,\n",
    "        check=check, bs=bs,\n",
    "        shuffle=True)\n",
    "    test_dl = make_cifar_dl(\n",
    "        cifar_dsets.CIFAR10.test_list,\n",
    "        path,\n",
    "        test_tfm,\n",
    "        check=check, bs=bs,\n",
    "        shuffle=False)\n",
    "    dls = DataLoaders(train_dl, test_dl, device=device)\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.cuda\n",
    "import torch\n",
    "device = torch.device(torch.cuda.current_device()) if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dls = make_fastai_cifar_dls(cifar_root, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#8) [Path('/root/.fastai/data/cifar/cifar-10-batches-py/data_batch_1'),Path('/root/.fastai/data/cifar/cifar-10-batches-py/data_batch_2'),Path('/root/.fastai/data/cifar/cifar-10-batches-py/readme.html'),Path('/root/.fastai/data/cifar/cifar-10-batches-py/batches.meta'),Path('/root/.fastai/data/cifar/cifar-10-batches-py/test_batch'),Path('/root/.fastai/data/cifar/cifar-10-batches-py/data_batch_4'),Path('/root/.fastai/data/cifar/cifar-10-batches-py/data_batch_5'),Path('/root/.fastai/data/cifar/cifar-10-batches-py/data_batch_3')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cifar_root/'cifar-10-batches-py').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
       " ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
       " ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
       " ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
       " ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_dsets.CIFAR10.train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = cifar_dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_dls.train.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data.core.TfmdLists"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifar_dls.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(cifar_dls, 'device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_dls.device is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('.')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_dls.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(cifar_dls.loaders[0],'to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_dls.loaders[0].device is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import fastai.callback.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = cnn_learner(cifar_dls, resnet18, n_out=10, pretrained=False, \n",
    "                      normalize=False,\n",
    "                      loss_func=nn.CrossEntropyLoss(),metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fit\n",
      "   - before_fit     : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "  Start Epoch Loop\n",
      "     - before_epoch   : [Recorder, ProgressCallback]\n",
      "    Start Train\n",
      "       - before_train   : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - before_batch   : []\n",
      "         - after_pred     : []\n",
      "         - after_loss     : []\n",
      "         - before_backward: []\n",
      "         - before_step    : []\n",
      "         - after_step     : []\n",
      "         - after_cancel_batch: []\n",
      "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      End Batch Loop\n",
      "    End Train\n",
      "     - after_cancel_train: [Recorder]\n",
      "     - after_train    : [Recorder, ProgressCallback]\n",
      "    Start Valid\n",
      "       - before_validate: [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - **CBs same as train batch**: []\n",
      "      End Batch Loop\n",
      "    End Valid\n",
      "     - after_cancel_validate: [Recorder]\n",
      "     - after_validate : [Recorder, ProgressCallback]\n",
      "  End Epoch Loop\n",
      "   - after_cancel_epoch: []\n",
      "   - after_epoch    : [Recorder]\n",
      "End Fit\n",
      " - after_cancel_fit: []\n",
      " - after_fit      : [ProgressCallback]\n"
     ]
    }
   ],
   "source": [
    "learner.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Sequential (Input shape: 64)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     64 x 64 x 16 x 16   \n",
       "Conv2d                                    9408       True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 128 x 4 x 4    \n",
       "Conv2d                                    73728      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    8192       True      \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 256 x 2 x 2    \n",
       "Conv2d                                    294912     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    32768      True      \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 512 x 1 x 1    \n",
       "Conv2d                                    1179648    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    131072     True      \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "AdaptiveAvgPool2d                                              \n",
       "AdaptiveMaxPool2d                                              \n",
       "Flatten                                                        \n",
       "BatchNorm1d                               2048       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 512            \n",
       "Linear                                    524288     True      \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               1024       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     64 x 10             \n",
       "Linear                                    5120       True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 11,708,992\n",
       "Total trainable params: 11,708,992\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: <function Adam at 0x7fd7bc7e2e18>\n",
       "Loss function: CrossEntropyLoss()\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.889744</td>\n",
       "      <td>1.896039</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.525709</td>\n",
       "      <td>1.402483</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.160433</td>\n",
       "      <td>1.045405</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.002535</td>\n",
       "      <td>0.890528</td>\n",
       "      <td>0.687900</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.874758</td>\n",
       "      <td>0.821122</td>\n",
       "      <td>0.709400</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 38s, sys: 3.3 s, total: 2min 42s\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "learner.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
