{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Explore_TPU_MNIST_Tiny_SGD-run2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1txZAfoWFN_-TWNy2Dl3AqkxRBMS-zeCO",
      "authorship_tag": "ABX9TyPFg9sq2hBiqAcr3ymOJQ/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70bd11678c4e4e2d9c48f191d5eabc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5fa997a81f54f359d8963e562241c42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_298b250be7f74bcca56dfcb36a6f2849",
              "IPY_MODEL_c05e18bac2e54309bda1a8d3f311816c"
            ]
          }
        },
        "e5fa997a81f54f359d8963e562241c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "298b250be7f74bcca56dfcb36a6f2849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7457ecf37c74ab884be5d91da3d10aa",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b661666d3ca345e4a491abfdc1564a7d"
          }
        },
        "c05e18bac2e54309bda1a8d3f311816c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd58d3ea24e14547877e351cbe624ba7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [02:11&lt;00:00, 357kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df8f81c512be49d2bf6a3e8a72c5e03a"
          }
        },
        "b7457ecf37c74ab884be5d91da3d10aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b661666d3ca345e4a491abfdc1564a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd58d3ea24e14547877e351cbe624ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df8f81c512be49d2bf6a3e8a72c5e03a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/explore_nbs/Explore_TPU_MNIST_Tiny_SGD_run2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM703MEF1orN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d41d005c-0149-4568-c9a7-9b8d69814c4f"
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzDnzKRe2sp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9fDYfqv3Cj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hATs2eDr3RTW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37272c52-fce8-4fbd-c00b-8d17b66016f0"
      },
      "source": [
        "VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  4139    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4139  100  4139    0     0  44031      0 --:--:-- --:--:-- --:--:-- 44031\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200325 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (1.12.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.3)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
            "Uninstalling torch-1.5.1+cu101:\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (47.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.9)\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.5.1+cu101\n",
            "Uninstalling torchvision-0.6.1+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 83.4 MiB/ 83.4 MiB]                                                \n",
            "Operation completed over 1 objects/83.4 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][114.5 MiB/114.5 MiB]                                                \n",
            "Operation completed over 1 objects/114.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n",
            "Processing ./torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (1.18.5)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.5.0a0+d6149a7\n",
            "Processing ./torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+e788e5b\n",
            "Processing ./torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (7.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.5.0a0+d6149a7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200325) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.6.0a0+3c254fb\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (391 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbNXNmzw3daU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fastai2 --upgrade > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy-t6zpR3gu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "272896d6-18e6-4f06-d56b-989ca2d3d171"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/fastai_xla_extensions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/fastai_xla_extensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9icnTUa3076",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5bef3059-de9f-4d7e-8d17-f0694a084738"
      },
      "source": [
        "!pip install -e \".[dev]\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/drive/My%20Drive/fastai_xla_extensions\n",
            "\u001b[33m  WARNING: fastai-xla-extensions 0.0.1 does not provide the extra 'dev'\u001b[0m\n",
            "Requirement already satisfied: fastai2 in /usr/local/lib/python3.6/dist-packages (from fastai-xla-extensions==0.0.1) (0.0.17)\n",
            "Collecting nbdev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/54/f39f9050f0e1610c4c5f764872812ef72615dac70ea7f1c9bc20948acb04/nbdev-0.2.18-py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (1.0.5)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.1.18)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (3.13)\n",
            "Requirement already satisfied: fastprogress>=0.1.22 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.2.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (2.2.4)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.6.0a0+3c254fb)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (1.5.0a0+d6149a7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from nbdev->fastai-xla-extensions==0.0.1) (5.0.7)\n",
            "Collecting fastscript\n",
            "  Downloading https://files.pythonhosted.org/packages/55/0e/ecdc0213646bc82986884121109a38b50bbc2cd2c491bbbfdc7ae39228e3/fastscript-0.1.4-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from nbdev->fastai-xla-extensions==0.0.1) (20.4)\n",
            "Requirement already satisfied: nbconvert>=5.6.1 in /usr/local/lib/python3.6/dist-packages (from nbdev->fastai-xla-extensions==0.0.1) (5.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->fastai-xla-extensions==0.0.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->fastai-xla-extensions==0.0.1) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->fastai-xla-extensions==0.0.1) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2->fastai-xla-extensions==0.0.1) (0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (47.3.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (0.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.5->fastai2->fastai-xla-extensions==0.0.1) (1.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2->fastai-xla-extensions==0.0.1) (0.15.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->fastai2->fastai-xla-extensions==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (2.4.7)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->fastai-xla-extensions==0.0.1) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->fastai-xla-extensions==0.0.1) (4.6.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->fastai-xla-extensions==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->fastai-xla-extensions==0.0.1) (2.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (3.1.5)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (2.11.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.4.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (2.1.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (1.4.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2->fastai-xla-extensions==0.0.1) (1.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1->nbformat>=4.4.0->nbdev->fastai-xla-extensions==0.0.1) (4.4.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2->fastai-xla-extensions==0.0.1) (3.1.0)\n",
            "Installing collected packages: fastscript, nbdev, fastai-xla-extensions\n",
            "  Running setup.py develop for fastai-xla-extensions\n",
            "Successfully installed fastai-xla-extensions fastscript-0.1.4 nbdev-0.2.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBMaggEHGbzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fa68eba-e863-4af6-ab23-2cdee2ce2aaf"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZzGjv7B5dJf",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QpyaqUC5ibo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.vision.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5aaUEx-5nNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsuq2V8LHr7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b043b51-980c-4cc7-8d50-61d8b697d1ee"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/fastai_xla_extensions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/fastai_xla_extensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-mNGiOC5yKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai_xla_extensions.core import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4xZl5AdHzga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76918ddd-3260-4429-d6aa-8cf640947de0"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4THQ3Hk056iJ",
        "colab_type": "text"
      },
      "source": [
        "### Setup data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMPe61C25_33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8c5ee8e9-066a-41ed-bb00-83c48d650eb9"
      },
      "source": [
        "path = untar_data(URLs.MNIST_TINY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChXTdufM6MXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock = DataBlock(\n",
        "    blocks=(ImageBlock(cls=PILImageBW),CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(),\n",
        "    item_tfms=Resize(28),\n",
        "    batch_tfms=[]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wBIWOB6WGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "06c1fd9e-8bdb-42d3-ed05-9c2f895a74a1"
      },
      "source": [
        "datablock.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_tiny\n",
            "Found 1428 items\n",
            "2 datasets of sizes 709,699\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_tiny/train/7/7644.png\n",
            "    applying PILBase.create gives\n",
            "      PILImageBW mode=L size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_tiny/train/7/7644.png\n",
            "    applying parent_label gives\n",
            "      7\n",
            "    applying Categorize gives\n",
            "      TensorCategory(1)\n",
            "\n",
            "Final sample: (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
            "    applying Resize gives\n",
            "      (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
            "    applying ToTensor gives\n",
            "      (TensorImageBW of size 1x28x28, TensorCategory(1))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor\n",
            "    starting from\n",
            "      (TensorImageBW of size 4x1x28x28, TensorCategory([1, 1, 1, 1]))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImageBW of size 4x1x28x28, TensorCategory([1, 1, 1, 1]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWfuYAsw7AGZ",
        "colab_type": "text"
      },
      "source": [
        "### Setup TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbY91nOu7HFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpu = xm.xla_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34YlwcCt7kcK",
        "colab_type": "text"
      },
      "source": [
        "### Setup DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyuC8el56a73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls = datablock.dataloaders(path, device=tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOgz8KcJ6g7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "c1f48f30-0786-4c73-e55e-3678ec9db92a"
      },
      "source": [
        "dls.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6UnAd4n7UZS",
        "colab_type": "text"
      },
      "source": [
        "### Create Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0qOorI67vLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func = XLAOptFuncWrapper(SGD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OQAeuRf6jgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "70bd11678c4e4e2d9c48f191d5eabc91",
            "e5fa997a81f54f359d8963e562241c42",
            "298b250be7f74bcca56dfcb36a6f2849",
            "c05e18bac2e54309bda1a8d3f311816c",
            "b7457ecf37c74ab884be5d91da3d10aa",
            "b661666d3ca345e4a491abfdc1564a7d",
            "bd58d3ea24e14547877e351cbe624ba7",
            "df8f81c512be49d2bf6a3e8a72c5e03a"
          ]
        },
        "outputId": "ae3bc64b-5922-42a1-f4c3-a1ecd86b0c1f"
      },
      "source": [
        "learner = cnn_learner(dls,resnet18,metrics=accuracy,opt_func=opt_func)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70bd11678c4e4e2d9c48f191d5eabc91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbP18tG276-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4df2f68b-ff73-43ec-fa41-7f25fbf118e3"
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "Sequential (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 64 x 14 x 14    9,408      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 14 x 14    128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 14 x 14    0          False     \n",
              "________________________________________________________________\n",
              "MaxPool2d            64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     73,728     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     8,192      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     294,912    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     32,768     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     1,179,648  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     131,072    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "AdaptiveAvgPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "AdaptiveMaxPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Flatten              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 1024            2,048      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 512             524,288    True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 512             1,024      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               1,024      True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 11,704,896\n",
              "Total trainable params: 537,984\n",
              "Total non-trainable params: 11,166,912\n",
              "\n",
              "Optimizer used: <fastai_xla_extensions.core.XLAOptFuncWrapper object at 0x7f0aa911ebe0>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Model frozen up to parameter group number 2\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M3g5czi8CF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "532d61bb-6670-4766-9a24-d682a427de8a"
      },
      "source": [
        "learner.fit(1,lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.230996</td>\n",
              "      <td>0.648106</td>\n",
              "      <td>0.605150</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otb9ibVk8Ii8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b6c6612-a4c4-4458-dca3-14733938521a"
      },
      "source": [
        "learner.fit(100,lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.065354</td>\n",
              "      <td>0.693843</td>\n",
              "      <td>0.580830</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.059621</td>\n",
              "      <td>0.763412</td>\n",
              "      <td>0.576538</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.991787</td>\n",
              "      <td>0.752729</td>\n",
              "      <td>0.595136</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.972316</td>\n",
              "      <td>0.704359</td>\n",
              "      <td>0.626609</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.937276</td>\n",
              "      <td>0.661739</td>\n",
              "      <td>0.663805</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.922108</td>\n",
              "      <td>0.605018</td>\n",
              "      <td>0.695279</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.902674</td>\n",
              "      <td>0.557938</td>\n",
              "      <td>0.718169</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.866847</td>\n",
              "      <td>0.540179</td>\n",
              "      <td>0.723891</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.834286</td>\n",
              "      <td>0.518274</td>\n",
              "      <td>0.743920</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.807816</td>\n",
              "      <td>0.492913</td>\n",
              "      <td>0.761087</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.777763</td>\n",
              "      <td>0.479560</td>\n",
              "      <td>0.768240</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.744537</td>\n",
              "      <td>0.468408</td>\n",
              "      <td>0.768240</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.711821</td>\n",
              "      <td>0.450958</td>\n",
              "      <td>0.776824</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.684725</td>\n",
              "      <td>0.435497</td>\n",
              "      <td>0.789700</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.665904</td>\n",
              "      <td>0.424272</td>\n",
              "      <td>0.793991</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.637015</td>\n",
              "      <td>0.413110</td>\n",
              "      <td>0.811159</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.635023</td>\n",
              "      <td>0.403854</td>\n",
              "      <td>0.814020</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.621417</td>\n",
              "      <td>0.383743</td>\n",
              "      <td>0.824034</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.592962</td>\n",
              "      <td>0.366151</td>\n",
              "      <td>0.832618</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.572147</td>\n",
              "      <td>0.357914</td>\n",
              "      <td>0.841202</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.547605</td>\n",
              "      <td>0.342954</td>\n",
              "      <td>0.858369</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.538485</td>\n",
              "      <td>0.339689</td>\n",
              "      <td>0.852647</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.525274</td>\n",
              "      <td>0.331388</td>\n",
              "      <td>0.862661</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.512651</td>\n",
              "      <td>0.323351</td>\n",
              "      <td>0.866953</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.502342</td>\n",
              "      <td>0.312515</td>\n",
              "      <td>0.866953</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.493423</td>\n",
              "      <td>0.305827</td>\n",
              "      <td>0.872675</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.477223</td>\n",
              "      <td>0.296036</td>\n",
              "      <td>0.881259</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.459482</td>\n",
              "      <td>0.289275</td>\n",
              "      <td>0.884120</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.442567</td>\n",
              "      <td>0.278501</td>\n",
              "      <td>0.895565</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.426095</td>\n",
              "      <td>0.270713</td>\n",
              "      <td>0.892704</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.417575</td>\n",
              "      <td>0.270018</td>\n",
              "      <td>0.892704</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.406590</td>\n",
              "      <td>0.266826</td>\n",
              "      <td>0.898426</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.398312</td>\n",
              "      <td>0.269654</td>\n",
              "      <td>0.888412</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.388691</td>\n",
              "      <td>0.262713</td>\n",
              "      <td>0.898426</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.372821</td>\n",
              "      <td>0.256699</td>\n",
              "      <td>0.899857</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.365217</td>\n",
              "      <td>0.251293</td>\n",
              "      <td>0.905579</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.357424</td>\n",
              "      <td>0.243554</td>\n",
              "      <td>0.912732</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.354193</td>\n",
              "      <td>0.234120</td>\n",
              "      <td>0.912732</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.342589</td>\n",
              "      <td>0.230235</td>\n",
              "      <td>0.915594</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.335829</td>\n",
              "      <td>0.226649</td>\n",
              "      <td>0.912732</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.339651</td>\n",
              "      <td>0.225259</td>\n",
              "      <td>0.918455</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.327657</td>\n",
              "      <td>0.224881</td>\n",
              "      <td>0.915594</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.319642</td>\n",
              "      <td>0.213967</td>\n",
              "      <td>0.925608</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.309341</td>\n",
              "      <td>0.212818</td>\n",
              "      <td>0.922747</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.298396</td>\n",
              "      <td>0.213473</td>\n",
              "      <td>0.921316</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.303688</td>\n",
              "      <td>0.206623</td>\n",
              "      <td>0.924177</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.297134</td>\n",
              "      <td>0.202881</td>\n",
              "      <td>0.922747</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.298172</td>\n",
              "      <td>0.198733</td>\n",
              "      <td>0.931330</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.288300</td>\n",
              "      <td>0.193305</td>\n",
              "      <td>0.922747</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.283053</td>\n",
              "      <td>0.195939</td>\n",
              "      <td>0.925608</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.275555</td>\n",
              "      <td>0.198204</td>\n",
              "      <td>0.925608</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.274021</td>\n",
              "      <td>0.192238</td>\n",
              "      <td>0.931330</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.258873</td>\n",
              "      <td>0.189252</td>\n",
              "      <td>0.927039</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.253157</td>\n",
              "      <td>0.186394</td>\n",
              "      <td>0.927039</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.252650</td>\n",
              "      <td>0.183197</td>\n",
              "      <td>0.928469</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.259765</td>\n",
              "      <td>0.180805</td>\n",
              "      <td>0.932761</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.245242</td>\n",
              "      <td>0.179939</td>\n",
              "      <td>0.937053</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.241223</td>\n",
              "      <td>0.182146</td>\n",
              "      <td>0.929900</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.235915</td>\n",
              "      <td>0.182316</td>\n",
              "      <td>0.931330</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.233967</td>\n",
              "      <td>0.179449</td>\n",
              "      <td>0.931330</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.231835</td>\n",
              "      <td>0.172699</td>\n",
              "      <td>0.931330</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.223512</td>\n",
              "      <td>0.170129</td>\n",
              "      <td>0.937053</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.221027</td>\n",
              "      <td>0.170787</td>\n",
              "      <td>0.934192</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.218589</td>\n",
              "      <td>0.168554</td>\n",
              "      <td>0.937053</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.211731</td>\n",
              "      <td>0.169889</td>\n",
              "      <td>0.934192</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.206193</td>\n",
              "      <td>0.168821</td>\n",
              "      <td>0.935622</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.210433</td>\n",
              "      <td>0.162137</td>\n",
              "      <td>0.935622</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.208015</td>\n",
              "      <td>0.165912</td>\n",
              "      <td>0.938484</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.208734</td>\n",
              "      <td>0.162591</td>\n",
              "      <td>0.937053</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.211335</td>\n",
              "      <td>0.160866</td>\n",
              "      <td>0.945637</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.208011</td>\n",
              "      <td>0.158706</td>\n",
              "      <td>0.941345</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.205489</td>\n",
              "      <td>0.156119</td>\n",
              "      <td>0.944206</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.201304</td>\n",
              "      <td>0.153341</td>\n",
              "      <td>0.947067</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.193723</td>\n",
              "      <td>0.159818</td>\n",
              "      <td>0.938484</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.192209</td>\n",
              "      <td>0.154060</td>\n",
              "      <td>0.949928</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.196481</td>\n",
              "      <td>0.150791</td>\n",
              "      <td>0.948498</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.187093</td>\n",
              "      <td>0.154158</td>\n",
              "      <td>0.942775</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.182988</td>\n",
              "      <td>0.152956</td>\n",
              "      <td>0.947067</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.178295</td>\n",
              "      <td>0.152406</td>\n",
              "      <td>0.944206</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.173923</td>\n",
              "      <td>0.148392</td>\n",
              "      <td>0.948498</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.169648</td>\n",
              "      <td>0.148268</td>\n",
              "      <td>0.952790</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.169028</td>\n",
              "      <td>0.148197</td>\n",
              "      <td>0.947067</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.166632</td>\n",
              "      <td>0.145873</td>\n",
              "      <td>0.948498</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.166294</td>\n",
              "      <td>0.147856</td>\n",
              "      <td>0.951359</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.162628</td>\n",
              "      <td>0.142418</td>\n",
              "      <td>0.947067</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.155846</td>\n",
              "      <td>0.144958</td>\n",
              "      <td>0.952790</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.151169</td>\n",
              "      <td>0.138161</td>\n",
              "      <td>0.955651</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.153903</td>\n",
              "      <td>0.137559</td>\n",
              "      <td>0.957082</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.157052</td>\n",
              "      <td>0.139600</td>\n",
              "      <td>0.951359</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.153190</td>\n",
              "      <td>0.139783</td>\n",
              "      <td>0.954220</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.156714</td>\n",
              "      <td>0.134831</td>\n",
              "      <td>0.958512</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.150150</td>\n",
              "      <td>0.133222</td>\n",
              "      <td>0.957082</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.154402</td>\n",
              "      <td>0.134458</td>\n",
              "      <td>0.955651</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.149811</td>\n",
              "      <td>0.133580</td>\n",
              "      <td>0.958512</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.146865</td>\n",
              "      <td>0.133835</td>\n",
              "      <td>0.955651</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.142398</td>\n",
              "      <td>0.130257</td>\n",
              "      <td>0.957082</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.141112</td>\n",
              "      <td>0.129447</td>\n",
              "      <td>0.958512</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.138976</td>\n",
              "      <td>0.126784</td>\n",
              "      <td>0.959943</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.140407</td>\n",
              "      <td>0.125456</td>\n",
              "      <td>0.962804</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.137929</td>\n",
              "      <td>0.125487</td>\n",
              "      <td>0.958512</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmmNsJqF9ujS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "36f071d2-f75a-4e73-851c-00b2683f40a4"
      },
      "source": [
        "learner.recorder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpDqEdVw-tnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('100epoch-tpu')\n",
        "# not saving?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gVVB8eHJIW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIhW7ens-3pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p /content/drive/My\\ Drive/fastai_v4/models/mnist_tiny_resnet18\n",
        "!cp /content/models/100epoch-tpu.pth /content/drive/My\\ Drive/fastai_v4/models/mnist_tiny_resnet18/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1bAfWVlJe_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9SvFEaGJjKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3566c4c-b872-4ade-9e09-024c2edd4b02"
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "Sequential (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 64 x 14 x 14    9,408      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 14 x 14    128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 14 x 14    0          False     \n",
              "________________________________________________________________\n",
              "MaxPool2d            64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     73,728     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     8,192      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     294,912    True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     32,768     True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     1,179,648  True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     131,072    True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  True      \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "AdaptiveAvgPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "AdaptiveMaxPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Flatten              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 1024            2,048      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 512             524,288    True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 512             1,024      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               1,024      True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 11,704,896\n",
              "Total trainable params: 11,023,744\n",
              "Total non-trainable params: 681,152\n",
              "\n",
              "Optimizer used: <fastai_xla_extensions.core.XLAOptFuncWrapper object at 0x7f0aa911ebe0>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Model frozen up to parameter group number 1\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p85fKwXRJmWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "b3c4ad25-9986-441f-c4be-8de4baa35961"
      },
      "source": [
        "learner.fit(1,lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.146425</td>\n",
              "      <td>0.114161</td>\n",
              "      <td>0.967096</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2ArOb-rJ-CF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebff3c37-7228-4e12-9562-3b402c03fa0f"
      },
      "source": [
        "learner.fit(100,lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.112040</td>\n",
              "      <td>0.109571</td>\n",
              "      <td>0.965665</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.118091</td>\n",
              "      <td>0.101155</td>\n",
              "      <td>0.969957</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.104056</td>\n",
              "      <td>0.101272</td>\n",
              "      <td>0.968526</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.100357</td>\n",
              "      <td>0.095231</td>\n",
              "      <td>0.969957</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.087324</td>\n",
              "      <td>0.095465</td>\n",
              "      <td>0.969957</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.078421</td>\n",
              "      <td>0.096893</td>\n",
              "      <td>0.968526</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.071802</td>\n",
              "      <td>0.092348</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.067457</td>\n",
              "      <td>0.091305</td>\n",
              "      <td>0.969957</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.063817</td>\n",
              "      <td>0.089002</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.059547</td>\n",
              "      <td>0.085312</td>\n",
              "      <td>0.971388</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.058245</td>\n",
              "      <td>0.081415</td>\n",
              "      <td>0.971388</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.056229</td>\n",
              "      <td>0.085139</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.052196</td>\n",
              "      <td>0.086467</td>\n",
              "      <td>0.971388</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.047898</td>\n",
              "      <td>0.080892</td>\n",
              "      <td>0.971388</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.042621</td>\n",
              "      <td>0.079449</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.040770</td>\n",
              "      <td>0.079204</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.036307</td>\n",
              "      <td>0.079033</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.035298</td>\n",
              "      <td>0.077475</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.035355</td>\n",
              "      <td>0.075397</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.032060</td>\n",
              "      <td>0.076854</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.029610</td>\n",
              "      <td>0.074670</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.029132</td>\n",
              "      <td>0.073384</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.026582</td>\n",
              "      <td>0.075915</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.026005</td>\n",
              "      <td>0.076598</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.025902</td>\n",
              "      <td>0.079675</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.024677</td>\n",
              "      <td>0.075262</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.024456</td>\n",
              "      <td>0.076480</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.026500</td>\n",
              "      <td>0.072529</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.023029</td>\n",
              "      <td>0.071971</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.021978</td>\n",
              "      <td>0.075382</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.021760</td>\n",
              "      <td>0.073733</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.019376</td>\n",
              "      <td>0.078748</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.018381</td>\n",
              "      <td>0.076701</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.017356</td>\n",
              "      <td>0.075628</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.016880</td>\n",
              "      <td>0.075706</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.016017</td>\n",
              "      <td>0.077889</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.019828</td>\n",
              "      <td>0.075960</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.017893</td>\n",
              "      <td>0.076195</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.015910</td>\n",
              "      <td>0.072614</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.016072</td>\n",
              "      <td>0.072693</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.014388</td>\n",
              "      <td>0.072110</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.013433</td>\n",
              "      <td>0.072138</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.012407</td>\n",
              "      <td>0.072605</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.015123</td>\n",
              "      <td>0.072222</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.013518</td>\n",
              "      <td>0.071740</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.013881</td>\n",
              "      <td>0.071406</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.013387</td>\n",
              "      <td>0.072088</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.013948</td>\n",
              "      <td>0.068239</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.013262</td>\n",
              "      <td>0.069549</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.013872</td>\n",
              "      <td>0.068437</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.012998</td>\n",
              "      <td>0.069095</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.012083</td>\n",
              "      <td>0.072286</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.011350</td>\n",
              "      <td>0.069927</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.010540</td>\n",
              "      <td>0.067407</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.009703</td>\n",
              "      <td>0.067032</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.010826</td>\n",
              "      <td>0.069276</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.010704</td>\n",
              "      <td>0.067022</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.010430</td>\n",
              "      <td>0.072442</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.009447</td>\n",
              "      <td>0.069371</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.009821</td>\n",
              "      <td>0.072138</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.009538</td>\n",
              "      <td>0.066761</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.009104</td>\n",
              "      <td>0.069457</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.009206</td>\n",
              "      <td>0.067678</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.010119</td>\n",
              "      <td>0.062779</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.008964</td>\n",
              "      <td>0.065620</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.008462</td>\n",
              "      <td>0.066705</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.008859</td>\n",
              "      <td>0.066500</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.008856</td>\n",
              "      <td>0.070134</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.008681</td>\n",
              "      <td>0.068997</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.008443</td>\n",
              "      <td>0.068278</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.008924</td>\n",
              "      <td>0.071813</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.068757</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.007281</td>\n",
              "      <td>0.071158</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.006763</td>\n",
              "      <td>0.066231</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.006595</td>\n",
              "      <td>0.069656</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.006565</td>\n",
              "      <td>0.066013</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.007468</td>\n",
              "      <td>0.071699</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.006676</td>\n",
              "      <td>0.069240</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.007156</td>\n",
              "      <td>0.072831</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.006413</td>\n",
              "      <td>0.069059</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.006159</td>\n",
              "      <td>0.071325</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.006232</td>\n",
              "      <td>0.073545</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.005570</td>\n",
              "      <td>0.072660</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.006368</td>\n",
              "      <td>0.071555</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.006421</td>\n",
              "      <td>0.069282</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.070121</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.006232</td>\n",
              "      <td>0.072093</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.005568</td>\n",
              "      <td>0.071351</td>\n",
              "      <td>0.974249</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.004929</td>\n",
              "      <td>0.067722</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.004305</td>\n",
              "      <td>0.068658</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.004139</td>\n",
              "      <td>0.068829</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.004521</td>\n",
              "      <td>0.068928</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.004517</td>\n",
              "      <td>0.068481</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.004744</td>\n",
              "      <td>0.068836</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.005073</td>\n",
              "      <td>0.069613</td>\n",
              "      <td>0.975680</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.068876</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.004473</td>\n",
              "      <td>0.066416</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.006234</td>\n",
              "      <td>0.071209</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.006034</td>\n",
              "      <td>0.070863</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.005784</td>\n",
              "      <td>0.068662</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-hr_okgKEdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('200epoch-tpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ge8ORRRLjtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/models/200epoch-tpu.pth /content/drive/My\\ Drive/fastai_v4/models/mnist_tiny_resnet18/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNexeu4ML2QV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GadZ8XxoMF9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "b35ed686-59bb-48e5-911d-7e696f5c6277"
      },
      "source": [
        "learner.fit(1,1e-4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.014966</td>\n",
              "      <td>0.411798</td>\n",
              "      <td>0.872675</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywr7x9CNMNbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06c04c94-3de7-4249-9933-4b51cd843805"
      },
      "source": [
        "learner.load('200epoch-tpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai2.learner.Learner at 0x7f0aa69c54e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A7EcAteMWda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSaCZ1DaMb85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "99f8dc2d-6ef2-4ed7-e709-291c33000084"
      },
      "source": [
        "learner.fit(1,3e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.035181</td>\n",
              "      <td>0.087136</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVwexLKvMie4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "959f0b71-55fd-405b-85cf-ad5a22da9fae"
      },
      "source": [
        "learner.fit(100,3e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.031167</td>\n",
              "      <td>0.104968</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.033027</td>\n",
              "      <td>0.055014</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.028160</td>\n",
              "      <td>0.050218</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.047010</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.021405</td>\n",
              "      <td>0.044869</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.022267</td>\n",
              "      <td>0.046296</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.022523</td>\n",
              "      <td>0.055260</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.020898</td>\n",
              "      <td>0.067925</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.018676</td>\n",
              "      <td>0.069919</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.017434</td>\n",
              "      <td>0.070361</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.019377</td>\n",
              "      <td>0.051265</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.019972</td>\n",
              "      <td>0.066615</td>\n",
              "      <td>0.982833</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.018601</td>\n",
              "      <td>0.066025</td>\n",
              "      <td>0.982833</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.017529</td>\n",
              "      <td>0.068296</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.017041</td>\n",
              "      <td>0.052686</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.014363</td>\n",
              "      <td>0.050195</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.013466</td>\n",
              "      <td>0.053525</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.011671</td>\n",
              "      <td>0.057508</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.011409</td>\n",
              "      <td>0.053539</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.013662</td>\n",
              "      <td>0.056869</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.012859</td>\n",
              "      <td>0.046437</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.010916</td>\n",
              "      <td>0.043180</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.010560</td>\n",
              "      <td>0.040862</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.015519</td>\n",
              "      <td>0.049178</td>\n",
              "      <td>0.982833</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.013863</td>\n",
              "      <td>0.040889</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.012683</td>\n",
              "      <td>0.041744</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.011527</td>\n",
              "      <td>0.044986</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.009946</td>\n",
              "      <td>0.043697</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.009531</td>\n",
              "      <td>0.042169</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.009037</td>\n",
              "      <td>0.039436</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.008129</td>\n",
              "      <td>0.043192</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.007992</td>\n",
              "      <td>0.041392</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.007346</td>\n",
              "      <td>0.048652</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.007120</td>\n",
              "      <td>0.043051</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.007248</td>\n",
              "      <td>0.043739</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.006283</td>\n",
              "      <td>0.042965</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.005892</td>\n",
              "      <td>0.047869</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.005294</td>\n",
              "      <td>0.045651</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.005212</td>\n",
              "      <td>0.047008</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.006627</td>\n",
              "      <td>0.048744</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.048722</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.005328</td>\n",
              "      <td>0.045941</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.004992</td>\n",
              "      <td>0.049705</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.004356</td>\n",
              "      <td>0.043392</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.003848</td>\n",
              "      <td>0.043800</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.003669</td>\n",
              "      <td>0.042857</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.003463</td>\n",
              "      <td>0.043956</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.003967</td>\n",
              "      <td>0.044583</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.004500</td>\n",
              "      <td>0.043062</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.004065</td>\n",
              "      <td>0.044036</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0.044475</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.003485</td>\n",
              "      <td>0.042044</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.003169</td>\n",
              "      <td>0.041360</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.003451</td>\n",
              "      <td>0.037568</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.003315</td>\n",
              "      <td>0.034128</td>\n",
              "      <td>0.992847</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.003652</td>\n",
              "      <td>0.040828</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.003668</td>\n",
              "      <td>0.038978</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.005859</td>\n",
              "      <td>0.038192</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.005322</td>\n",
              "      <td>0.039664</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.004589</td>\n",
              "      <td>0.040225</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.004005</td>\n",
              "      <td>0.044272</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.003645</td>\n",
              "      <td>0.043636</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.003311</td>\n",
              "      <td>0.044826</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.002969</td>\n",
              "      <td>0.045202</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.003068</td>\n",
              "      <td>0.041988</td>\n",
              "      <td>0.992847</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.002697</td>\n",
              "      <td>0.041450</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.002979</td>\n",
              "      <td>0.041864</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>0.042129</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.002697</td>\n",
              "      <td>0.037882</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.002636</td>\n",
              "      <td>0.042656</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.002394</td>\n",
              "      <td>0.039816</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.038694</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.002403</td>\n",
              "      <td>0.040216</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.002816</td>\n",
              "      <td>0.033639</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.002919</td>\n",
              "      <td>0.035030</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.003564</td>\n",
              "      <td>0.037572</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.003314</td>\n",
              "      <td>0.036916</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.004073</td>\n",
              "      <td>0.039331</td>\n",
              "      <td>0.991416</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.003608</td>\n",
              "      <td>0.037543</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.003277</td>\n",
              "      <td>0.036753</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.003071</td>\n",
              "      <td>0.035902</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.002823</td>\n",
              "      <td>0.039015</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.003237</td>\n",
              "      <td>0.040511</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.003383</td>\n",
              "      <td>0.036058</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>0.044602</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.009128</td>\n",
              "      <td>0.042500</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.007929</td>\n",
              "      <td>0.045427</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.007040</td>\n",
              "      <td>0.040620</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.006358</td>\n",
              "      <td>0.042881</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.005643</td>\n",
              "      <td>0.045580</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.004890</td>\n",
              "      <td>0.044560</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.004615</td>\n",
              "      <td>0.040668</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.004109</td>\n",
              "      <td>0.040495</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.003966</td>\n",
              "      <td>0.038095</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.003590</td>\n",
              "      <td>0.040077</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.003196</td>\n",
              "      <td>0.041167</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.002788</td>\n",
              "      <td>0.041428</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.002568</td>\n",
              "      <td>0.041452</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.002403</td>\n",
              "      <td>0.041051</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.002043</td>\n",
              "      <td>0.041032</td>\n",
              "      <td>0.989986</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBdSYcTsN9UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('300epoch-tpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7no-qS1MqU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1445b3df-f4f6-4fad-9693-77da0550d193"
      },
      "source": [
        "learner.load('200epoch-tpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai2.learner.Learner at 0x7f0aa69c54e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kWjeRFdODiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXz5fmEQOHhw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2c84f62-7bba-4a4a-ac86-e1bbfb60e90e"
      },
      "source": [
        "learner.fit(55, 3e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.008216</td>\n",
              "      <td>0.082661</td>\n",
              "      <td>0.978541</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.015314</td>\n",
              "      <td>0.078784</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.030065</td>\n",
              "      <td>0.049561</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.030891</td>\n",
              "      <td>0.066259</td>\n",
              "      <td>0.982833</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.027684</td>\n",
              "      <td>0.061514</td>\n",
              "      <td>0.982833</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.024889</td>\n",
              "      <td>0.058910</td>\n",
              "      <td>0.981402</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.025746</td>\n",
              "      <td>0.051013</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.021031</td>\n",
              "      <td>0.046796</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.019237</td>\n",
              "      <td>0.049042</td>\n",
              "      <td>0.977110</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.018199</td>\n",
              "      <td>0.055279</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.016376</td>\n",
              "      <td>0.055614</td>\n",
              "      <td>0.982833</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.014019</td>\n",
              "      <td>0.050523</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.013163</td>\n",
              "      <td>0.052611</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.011586</td>\n",
              "      <td>0.063046</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.011789</td>\n",
              "      <td>0.053856</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.069297</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.014889</td>\n",
              "      <td>0.044563</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.013639</td>\n",
              "      <td>0.045218</td>\n",
              "      <td>0.981402</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.011926</td>\n",
              "      <td>0.043942</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.010224</td>\n",
              "      <td>0.043105</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.011545</td>\n",
              "      <td>0.061110</td>\n",
              "      <td>0.979971</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.011025</td>\n",
              "      <td>0.057348</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.012400</td>\n",
              "      <td>0.053963</td>\n",
              "      <td>0.981402</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.010819</td>\n",
              "      <td>0.044250</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.013562</td>\n",
              "      <td>0.050589</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.012637</td>\n",
              "      <td>0.056174</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.011117</td>\n",
              "      <td>0.053704</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.009846</td>\n",
              "      <td>0.057305</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.010154</td>\n",
              "      <td>0.051145</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.009382</td>\n",
              "      <td>0.054150</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.008595</td>\n",
              "      <td>0.055882</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.008351</td>\n",
              "      <td>0.047635</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.007502</td>\n",
              "      <td>0.043176</td>\n",
              "      <td>0.982833</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.006718</td>\n",
              "      <td>0.047770</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.005742</td>\n",
              "      <td>0.046129</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.005152</td>\n",
              "      <td>0.045735</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.004490</td>\n",
              "      <td>0.047463</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.004982</td>\n",
              "      <td>0.049753</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.004481</td>\n",
              "      <td>0.054610</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.005870</td>\n",
              "      <td>0.056735</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.005542</td>\n",
              "      <td>0.056267</td>\n",
              "      <td>0.982833</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.005782</td>\n",
              "      <td>0.049184</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.005408</td>\n",
              "      <td>0.059012</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.006677</td>\n",
              "      <td>0.066067</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.006376</td>\n",
              "      <td>0.062042</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.005790</td>\n",
              "      <td>0.060134</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.005318</td>\n",
              "      <td>0.053128</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.004749</td>\n",
              "      <td>0.057009</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.004316</td>\n",
              "      <td>0.054580</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.003960</td>\n",
              "      <td>0.055373</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.003798</td>\n",
              "      <td>0.050017</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.003562</td>\n",
              "      <td>0.049597</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.003803</td>\n",
              "      <td>0.054795</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.003973</td>\n",
              "      <td>0.060716</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.004124</td>\n",
              "      <td>0.066992</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWHRQm7ROSlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('355epoch-tpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oYunj4kPB2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a61d3835-49aa-48a1-ca70-ad5c12cdc0f7"
      },
      "source": [
        "learner.fit(5,1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.005608</td>\n",
              "      <td>0.066075</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.005501</td>\n",
              "      <td>0.063906</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.004303</td>\n",
              "      <td>0.065932</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.004243</td>\n",
              "      <td>0.059847</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.006342</td>\n",
              "      <td>0.059860</td>\n",
              "      <td>0.988555</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBgYr1VGPHjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('360epoch-tpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewpHbyf5PZj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "4f080f5c-d951-4c6c-da28-7dff446ac112"
      },
      "source": [
        "learner.fit(10,1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.002109</td>\n",
              "      <td>0.058249</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.002757</td>\n",
              "      <td>0.061543</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.003022</td>\n",
              "      <td>0.068762</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.003219</td>\n",
              "      <td>0.052798</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.002706</td>\n",
              "      <td>0.054890</td>\n",
              "      <td>0.984263</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.002749</td>\n",
              "      <td>0.051467</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.002318</td>\n",
              "      <td>0.052882</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.003774</td>\n",
              "      <td>0.052609</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.003264</td>\n",
              "      <td>0.052151</td>\n",
              "      <td>0.987124</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.002872</td>\n",
              "      <td>0.052232</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzcknp7sTC4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('370epoch-tpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg9Ex-uKTGhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/models/300epoch-tpu.pth  /content/drive/My\\ Drive/fastai_v4/models/mnist_tiny_resnet18/.\n",
        "!cp /content/models/355epoch-tpu.pth  /content/drive/My\\ Drive/fastai_v4/models/mnist_tiny_resnet18/.\n",
        "!cp /content/models/360epoch-tpu.pth  /content/drive/My\\ Drive/fastai_v4/models/mnist_tiny_resnet18/.\n",
        "!cp /content/models/370epoch-tpu.pth  /content/drive/My\\ Drive/fastai_v4/models/mnist_tiny_resnet18/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMt24oYzPfDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = learner.opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBCKTfcuRKAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "928f30d8-14aa-4dae-d3b1-cc079f5fb462"
      },
      "source": [
        "len(opt.param_lists)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ7eSwnYRYL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8bb7f567-8f95-4675-b172-35687f0b1669"
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-xFqKmXRlvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}